# Introgression Scans

## Download Intronets

I need [introNets](https://github.com/SchriderLab/introNets) version of ms (msmodified) to run the simulations. I download the folder from github and compile msmodified as suggested by Dylan.
```
cd src
git clone https://github.com/SchriderLab/introNets.git
cd introNets/msmodified
gcc -o ms ms.c streec.c rand1.c -lm
```
To setup a conda environment to run its scripts:
```
## create environment
# on genomics cluster
conda create --prefix=/home/ebazzicalupo/introNets/intronets python=3.9
conda activate /home/ebazzicalupo/introNets/intronets
# on cesga cluster
conda create --prefix=/mnt/netapp1/Store_CSIC/home/csic/eye/eba/intronets python=3.9
conda activate /mnt/netapp1/Store_CSIC/home/csic/eye/eba/intronets

# install stuff:
conda install -c conda-forge mpi4py openmpi
pip install "numpy<1.25"
pip install seriate
pip install scipy
pip install scikit-learn
pip install h5py
python -m pip install -U matplotlib
pip uninstall protobuf
pip install "protobuf<3.20"
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install pandas
pip install seaborn
pip install prettytable
```

## Simulate training data

To simulate the data for training the [simulate_data.py](src/introgression_scans/simulate_data.py) takes a YAML file (`--demes_yaml`) with the demographic model in demes format (generated by GADMA2), a CSV (`--confint`) with the confidence intervals around the parameters (generated by [plot_boot_params.py](src/demographic_inference/plot_boot_params.py)), and a migration scenario (`--migration`, see below), and outputs a specified number of simulations (`--nreps`) to an output directory (`--odir`), using a msmodified simulator (`--path_to_msmodified`).

The migration scenarios to be simulated are:
- ab: migration from population 1 (eurasian lynx) to population 2 (iberian lynx) in forward time (`-es Tmig 2 Pmig -ej Tmig 3 1`)
- ba: migration from population 2 (iberian lynx) to population 1 (eurasian lynx) in forward time (`-es Tmig 1 Pmig -ej Tmig 3 2`)
- abba: bidirectional migration, with first ab and then ba in forward time
- baab: bidiractional migration, with first ba and then ab in forward time
- none: no migration

The time of migration is set to be a random time between the present and 1/10th of the divergence time and the amount of migration is a random value between 0 and 0.5.

Both abba and baab will go into the 'bi' category for the discriminator, but are divided here because of how you need to specify the order of migrations in ms. This means we will simulate X ab, ba and none, and X/2 abba and baab for each demographic model.

```
pop_pair=lpa-wel

# for migration in ab ba bi none; do
#     mkdir data/introgression_scans/simulations/${pop_pair}_${migration}_sims/
# done
# 
# for model in 12_9 20_7 6_2; do
#     mkdir data/introgression_scans/simulations/${pop_pair}_ab_sims/${model}/
#     mkdir data/introgression_scans/simulations/${pop_pair}_ba_sims/${model}/
#     mkdir data/introgression_scans/simulations/${pop_pair}_bi_sims/${model}_abba/
#     mkdir data/introgression_scans/simulations/${pop_pair}_bi_sims/${model}_baab/
#     mkdir data/introgression_scans/simulations/${pop_pair}_none_sims/${model}/
# done

for model in 12_9 20_7 6_2; do
    for migration in ab ba none; do
        python src/introgression_scans/simulate_data.py \
            --demes_yaml data/demographic_inference/${pop_pair}_best_yamls/${pop_pair}_${model}_final_best_model.yaml \
            --confint data/demographic_inference/${pop_pair}_CI/${pop_pair}.${model}.CI.csv \
            --path_to_msmodified src/introNets/msmodified/ms \
            --migration ${migration} \
            --nreps 15000 \
            --odir data/introgression_scans/simulations/${pop_pair}_${migration}_sims/${model}/
    done
done

for model in 12_9 20_7 6_2; do
    for migration in abba baab; do
        python src/introgression_scans/simulate_data.py \
            --demes_yaml data/demographic_inference/${pop_pair}_best_yamls/${pop_pair}_${model}_final_best_model.yaml \
            --confint data/demographic_inference/${pop_pair}_CI/${pop_pair}.${model}.CI.csv \
            --path_to_msmodified src/introNets/msmodified/ms \
            --migration ${migration} \
            --nreps 7500 \
            --odir data/introgression_scans/simulations/${pop_pair}_bi_sims/${model}_${migration}/
    done
done
```

## Filter simulated data for training

I filter out from simulations the ones with < 128 segsites using [filter_sims.py](src/introgression_scans/filter_sims.py), or [introNets format.py](https://github.com/SchriderLab/introNets/blob/main/src/data/format.py) will throw errors and corrupt the hdf5 file:
```
pop_pair=lpa-wel

# for migration in ab ba bi none; do
#     mkdir data/introgression_scans/simulations/${pop_pair}_${migration}_filtered_sims/
# done
# 
# for model in 12_9 20_7 6_2; do
#     mkdir data/introgression_scans/simulations/${pop_pair}_ab_filtered_sims/${model}/
#     mkdir data/introgression_scans/simulations/${pop_pair}_ba_filtered_sims/${model}/
#     mkdir data/introgression_scans/simulations/${pop_pair}_bi_filtered_sims/${model}_abba/
#     mkdir data/introgression_scans/simulations/${pop_pair}_bi_filtered_sims/${model}_baab/
#     mkdir data/introgression_scans/simulations/${pop_pair}_none_filtered_sims/${model}/
# done

for model in 12_9 20_7 6_2; do
    for migration in ab ba none; do
        echo "filtering ${pop_pair}_${migration} of ${model}"
        python src/introgression_scans/filter_sims.py \
            --idir data/introgression_scans/simulations/${pop_pair}_${migration}_sims/${model}/ \
            --odir data/introgression_scans/simulations/${pop_pair}_${migration}_filtered_sims/${model}/ \
            --n_sites 128 --n_sims 10000
    done
done

for model in 12_9 20_7 6_2; do
    for migration in abba baab; do
        echo "filtering ${pop_pair}_${migration} of ${model}"
        python src/introgression_scans/filter_sims.py \
            --idir data/introgression_scans/simulations/${pop_pair}_bi_sims/${model}_${migration}/ \
            --odir data/introgression_scans/simulations/${pop_pair}_bi_filtered_sims/${model}_${migration}/ \
            --n_sites 128 --n_sims 5000
    done
done
```

## Format simulations

To format my simulations for training I run [introNets format.py](https://github.com/SchriderLab/introNets/blob/main/src/data/format.py):
```
conda activate ~/introNets/intronets
pop_pair=lpa-wel

mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations/${pop_pair}_ab_filtered_sims/ \
    --ofile data/introgression_scans/simulations/${pop_pair}_ab.hdf5 \
    --pop_sizes 40,44 --out_shape 2,44,128 --pop 1 |& tee logs/introgression_scans/format_ab.log

mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations/${pop_pair}_ba_filtered_sims/ \
    --ofile data/introgression_scans/simulations/${pop_pair}_ba.hdf5 \
    --pop_sizes 40,44 --out_shape 2,44,128 --pop 0 |& tee logs/introgression_scans/format_ba.log

mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations/${pop_pair}_bi_filtered_sims/ \
    --ofile data/introgression_scans/simulations/${pop_pair}_bi.hdf5 \
    --pop_sizes 40,44 --out_shape 2,44,128 --pop -1 |& tee logs/introgression_scans/format_bi.log

mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations/${pop_pair}_none_filtered_sims/ \
    --ofile data/introgression_scans/simulations/${pop_pair}_none.hdf5 \
    --pop_sizes 40,44 --out_shape 2,44,128 --include_zeros |& tee logs/introgression_scans/format_none.log
```

## Check formatted simulations

I can create a fasta file to visually check the formatted simulations to see if they make sense using [write_fastas_from_hdf5.py](src/introgression_scans/write_fastas_from_hdf5.py):
```
conda activate ~/introNets/intronets
pop_pair=lpa-wel

mkdir data/introgression_scans/simulations/fastas/
for mig in ab ba bi none; do
    mkdir data/introgression_scans/simulations/fastas/${pop_pair}_${mig}
done

for mig in ab ba bi none; do
    python src/introgression_scans/write_fastas_from_hdf5.py \
        --ifile data/introgression_scans/simulations/${pop_pair}_${mig}.hdf5 \
        --odir data/introgression_scans/simulations/fastas/${pop_pair}_${mig} \
        --nseqs 25
done
```

## Train a discriminator model

To train a discriminator of my 4 classes of introgression I run [introNets train_discriminator.py](https://github.com/SchriderLab/introNets/blob/main/src/models/train_discriminator.py):

```
script logs/introgression_scans/train_disc.log

conda activate ~/introNets/intronets
pop_pair=lpa-wel
taskset -c 1,2,3,4,5,6,7,8,9,10 \
    python src/introNets/src/models/train_discriminator.py \
        --idir data/introgression_scans/simulations/ --odir data/introgression_scans/discriminator/ --n_classes 4
```

## Evaluate the discriminator

TBD

## Real data preparation

To transform the real data (phased vcf) to a hdf5 file that can be analyzed by the discriminator I first convert it to numpy's [NPZ](https://imageio.readthedocs.io/en/v2.5.0/format_npz.html) format. For this I use the [phasedVcfToNpz.py](src/introgression_scans/phasedVcfToNpz.py) script wrote by Dan. When using this script the `species1` will be saved as `sechHeader` + `sechMatrix` and `species2` as `simHeader` + `simMatrix` in the NPZ (important for hdf5 formatting below). One separate NPZ file is generated for each chromosome:
```
# vcfdir
vcfdir=/GRUPOS/grupolince/mLynRuf2.2_ref_vcfs
# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))
# eurasian pop
pop=wel
# vcf
vcfFileName=${vcfdir}/lynxtrogression_v2.autosomic_scaffolds.filter4.lpa-${pop}.ps.phased.merged.concat.fixed.afan.rd_fil.variant.vcf
# species1 - eurasian lynx
species1ListFileName=data/${pop}.list
# species2 - iberian lynx
species2ListFileName=data/lpa.list
# reference genome (masked if needed - not our case)
maskedRefFileName=${refdir}/mLynRuf2.2.revcomp.scaffolds.fa

for chr in ${chrs[@]}; do
    # output file
    npzFileName=data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz
    echo "generating ${npzFileName}"
    # run script
    python src/introgression_scans/phasedVcfToNpz.py \
        $vcfFileName $species1ListFileName $species2ListFileName $maskedRefFileName $chr $npzFileName
done
```

I use [introNets format_npz.py](https://github.com/SchriderLab/introNets/blob/main/src/data/format_npz.py) to convert these files to hdf5. I set `--keys` to `sechMatrix,simMatrix` to have the eurasian lynx population as population1 and the iberian lynx population as population2.
```
conda activate ~/introNets/intronets

# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))
# eurasian pop
pop=wel

for chr in ${chrs[@]}; do
    in_npz=data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz
    out_hdf5=data/introgression_scans/hdf5_files/lpa-${pop}.${chr}.hdf5
    echo "generating ${out_hdf5}"
    mpirun -n 10 python src/introNets/src/data/format_npz.py \
        --verbose \
        --ifile ${in_npz} \
        --ofile ${out_hdf5} \
        --pop_sizes 40,44 --out_shape 2,44,128 \
        --keys sechMatrix,simMatrix
done
```

## NOT CURRENTLY WORKING - Apply discriminator to real data HDF5 - 

*THIS IS NOT WORKING AS INTENDED! THERE IS A BUG IN FORMAT_NPZ.PY*

To apply the discriminator model to the real data I wrote a modified version of [introNets apply_disc.py](https://github.com/SchriderLab/introNets/blob/main/src/models/apply_disc.py) which I located in the introNets folder for easier access to required imports. I put a copy of my version ([apply_disc_eb.py](src/introgression_scans/apply_disc_eb.py)) in this repo, but in order to work properly it has to be located in the `src/models/` folder of introNets.

```
conda activate ~/introNets/intronets

ifile=data/introgression_scans/hdf5_files/lpa-wel.mLynRuf2.2_ChrA1.hdf5
ofile=data/introgression_scans/lpa-wel_predictions/mLynRuf2.2_ChrA1.predictions.new.csv

python src/introNets/src/models/apply_disc_eb.py \
    --weights data/introgression_scans/discriminator/test.weights \
    --ifile ${ifile} \
    --ofile ${ofile}
```

## Apply discriminator to real data NPZ

Since there is a problem when generating the hdf5 file from npz data, until it's fixed I will use different script, [apply_disc_to_npz.py](src/introgression_scans/apply_disc_to_npz.py), that applies the model directly to the NPZ. This is not ideal since it's much slower in sorting the haplotypes in the windows because it's not being parallelized as in `format_npz.py`. I use it until the other is fixed. I placed a copy of it in the `src/models/` folder of introNets so it can load the model properly.

```
conda activate ~/introNets/intronets
pop=wel
# chr=mLynRuf2.2_ChrA1
# chr=mLynRuf2.2_ChrC1
# chr=mLynRuf2.2_ChrB1
# chr=mLynRuf2.2_ChrA2_rc
# chr=mLynRuf2.2_ChrC2
# chr=mLynRuf2.2_ChrB2_rc
# chr=mLynRuf2.2_ChrB3
# chr=mLynRuf2.2_ChrB4_rc
# chr=mLynRuf2.2_ChrA3_rc
# chr=mLynRuf2.2_ChrD1
# chr=mLynRuf2.2_ChrD4
# chr=mLynRuf2.2_ChrD3
# chr=mLynRuf2.2_ChrD2
# chr=mLynRuf2.2_ChrF2
# chr=mLynRuf2.2_ChrF1_rc
# chr=mLynRuf2.2_ChrE2_rc
# chr=mLynRuf2.2_ChrE1
# chr=mLynRuf2.2_ChrE3_rc

python src/introNets/src/models/apply_disc_to_npz.py \
    --ifile data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz \
    --ofile data/introgression_scans/lpa-${pop}_predictions/${chr}.predictions.csv \
    --weights data/introgression_scans/discriminator/test.weights \
    --pop_sizes 40,44 \
    --shape 2,44,128 \
    --step_size 64 \
    --in_channels 2 \
    --n_classes 4
```

## Create fastas from VCF to check predictions

To manually check predicted regions with introgression I run [src/introgression_scans/write_fastas_from_vcf.py](src/introgression_scans/write_fastas_from_vcf.py), then I can check them with an alignment viewer (I use [Jalview](https://www.jalview.org/)):
```
# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))
# vcfdir
vcfdir=/GRUPOS/grupolince/mLynRuf2.2_ref_vcfs
# eurasian pop
pop=wel
# ivcf
ivcf=${vcfdir}/lynxtrogression_v2.autosomic_scaffolds.filter4.lpa-${pop}.ps.phased.merged.concat.fixed.afan.rd_fil.variant.vcf

mkdir data/introgression_scans/lpa-${pop}_vcf_fastas/

for chr in ${chrs[@]}; do
    # mkdir data/introgression_scans/lpa-${pop}_vcf_fastas/${chr}
    python src/introgression_scans/write_fastas_from_vcf.py \
        --ivcf ${ivcf} \
        --chr ${chr} \
        --odir data/introgression_scans/lpa-${pop}_vcf_fastas/${chr} \
        --win_size 128 \
        --step_size 64
done
```