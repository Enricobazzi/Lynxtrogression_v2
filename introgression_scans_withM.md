# Introgression Scans

## Download Intronets

I need [introNets](https://github.com/SchriderLab/introNets) version of ms (msmodified) to run the simulations_withM. I download the folder from github and compile msmodified as suggested by Dylan.
```
cd src
git clone https://github.com/SchriderLab/introNets.git
cd introNets/msmodified
gcc -o ms ms.c streec.c rand1.c -lm
```
To setup a conda environment to run its scripts:
```
## create environment
# on genomics cluster
conda create --prefix=/home/ebazzicalupo/introNets/intronets python=3.9
conda activate /home/ebazzicalupo/introNets/intronets
# on cesga cluster
conda create --prefix=/mnt/netapp1/Store_CSIC/home/csic/eye/eba/intronets python=3.9
conda activate /mnt/netapp1/Store_CSIC/home/csic/eye/eba/intronets

# install stuff:
conda install -c conda-forge mpi4py openmpi
pip install "numpy<1.25"
pip install seriate
pip install scipy
pip install scikit-learn
pip install h5py
python -m pip install -U matplotlib
pip uninstall protobuf
pip install "protobuf<3.20"
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install pandas
pip install seaborn
pip install prettytable
```

## Simulate training data

To simulate the data for training the [simulate_data.py](src/introgression_scans/simulate_data.py) takes a YAML file (`--demes_yaml`) with the demographic model in demes format (generated by GADMA2), a CSV (`--confint`) with the confidence intervals around the parameters (generated by [plot_boot_params.py](src/demographic_inference/plot_boot_params.py)), and a migration scenario (`--migration`, see below), and outputs a specified number of simulations_withM (`--nreps`) to an output directory (`--odir`), using a msmodified simulator (`--path_to_msmodified`).

The migration scenarios to be simulated are:
- ab: migration from population 1 (eurasian lynx) to population 2 (iberian lynx) in forward time (`-es Tmig 2 Pmig -ej Tmig 3 1`)
- ba: migration from population 2 (iberian lynx) to population 1 (eurasian lynx) in forward time (`-es Tmig 1 Pmig -ej Tmig 3 2`)
- abba: bidirectional migration, with first ab and then ba in forward time
- baab: bidiractional migration, with first ba and then ab in forward time
- none: no migration

The time of migration is set to be a random time between the present and 5 thousand generations ago and the amount of migration is a random value between 0.05 and 0.5.

Both abba and baab will go into the 'bi' category for the discriminator, but are divided here because of how you need to specify the order of migrations in ms. This means we will simulate X ab, ba and none, and X/2 abba and baab for each demographic model.

```
conda activate lynxtrogression_v2
pop_pair=lpa-eel
pop_pair=lpa-sel
pop_pair=lpa-wel

if [ ${pop_pair} == 'lpa-wel' ]; then
    models=(12_9 6_2 20_7)
elif [ ${pop_pair} == 'lpa-eel' ]; then
    models=(34_7 38_4 30_1)
elif [ ${pop_pair} == 'lpa-sel' ]; then
    models=(12_6 18_7 18_10)
fi

for migration in ab ba bi none; do
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_sims/
done

for model in ${models[@]}; do
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_ab_sims/${model}/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_ba_sims/${model}/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_bi_sims/${model}_abba/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_bi_sims/${model}_baab/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_none_sims/${model}/
done

for migration in ab ba none; do
    for model in ${models[@]}; do
        python src/introgression_scans/simulate_data_withM.py \
            --demes_yaml data/demographic_inference/${pop_pair}_best_yamls/${pop_pair}_${model}_final_best_model.yaml \
            --confint data/demographic_inference/${pop_pair}_CI/${pop_pair}.${model}.CI.csv \
            --path_to_msmodified src/introNets/msmodified/ms \
            --migration ${migration} \
            --nreps 20000 \
            --odir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_sims/${model}/
    done
done

for migration in abba baab; do
    for model in ${models[@]}; do
        python src/introgression_scans/simulate_data.py \
            --demes_yaml data/demographic_inference/${pop_pair}_best_yamls/${pop_pair}_${model}_final_best_model.yaml \
            --confint data/demographic_inference/${pop_pair}_CI/${pop_pair}.${model}.CI.csv \
            --path_to_msmodified src/introNets/msmodified/ms \
            --migration ${migration} \
            --nreps 10000 \
            --odir data/introgression_scans/simulations_withM/${pop_pair}_bi_sims/${model}_${migration}/
    done
done
```

## Filter simulated data for training

I filter out from simulations_withM the ones with < 128 segsites using [filter_sims.py](src/introgression_scans/filter_sims.py), or [introNets format.py](https://github.com/SchriderLab/introNets/blob/main/src/data/format.py) will throw errors and corrupt the hdf5 file.

*ALSO CREATE 129 SEGSITES SIMS TO NOT HAVE ERROR IN FORMAT.PY*

```
conda activate lynxtrogression_v2
pop_pair=lpa-wel
pop_sizes="40,44"
conda activate lynxtrogression_v2
pop_pair=lpa-eel
pop_sizes="38,44"
conda activate lynxtrogression_v2
pop_pair=lpa-sel
pop_sizes="24,44"

if [ ${pop_pair} == 'lpa-wel' ]; then
    models=(12_9 6_2 20_7)
elif [ ${pop_pair} == 'lpa-eel' ]; then
    models=(34_7 38_4 30_1)
elif [ ${pop_pair} == 'lpa-sel' ]; then
    models=(12_6 18_7 18_10)
fi


for migration in ab ba bi none; do
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_filtered_sims/
done

for model in ${models[@]}; do
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_ab_filtered_sims/${model}/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_ba_filtered_sims/${model}/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_bi_filtered_sims/${model}_abba/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_bi_filtered_sims/${model}_baab/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_none_filtered_sims/${model}/
done

for migration in ab ba none; do
    for model in ${models[@]}; do
        echo "filtering ${pop_pair}_${migration} of ${model}"
        python src/introgression_scans/filter_sims.py \
            --idir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_sims/${model}/ \
            --odir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_filtered_sims/${model}/ \
            --n_sites 129 --n_sims 12000 --migration ${migration} --pop_sizes ${pop_sizes}
    done
done

for model in ${models[@]}; do
    for migration in abba baab; do
        echo "filtering ${pop_pair}_${migration} of ${model}"
        python src/introgression_scans/filter_sims.py \
            --idir data/introgression_scans/simulations_withM/${pop_pair}_bi_sims/${model}_${migration}/ \
            --odir data/introgression_scans/simulations_withM/${pop_pair}_bi_filtered_sims/${model}_${migration}/ \
            --n_sites 129 --n_sims 6000 --migration bi --pop_sizes ${pop_sizes}
    done
done
```

## Format simulations_withM

To format my simulations_withM for training I run [introNets format.py](https://github.com/SchriderLab/introNets/blob/main/src/data/format.py):
```
## ADD HDF5 FOLDER TO OFOLDER

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
conda activate ~/introNets/intronets
pop_pair=lpa-eel
pop_sizes="38,44"
conda activate ~/introNets/intronets
pop_pair=lpa-sel
pop_sizes="24,44"

mkdir data/introgression_scans/simulations_withM/${pop_pair}_hdf5s

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations_withM/${pop_pair}_ab_filtered_sims/ \
    --ofile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_ab.hdf5 \
    --pop_sizes ${pop_sizes} --out_shape 2,44,128 --pop 1 |& tee logs/introgression_scans/format_${pop_pair}_ab.log

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations_withM/${pop_pair}_ba_filtered_sims/ \
    --ofile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_ba.hdf5 \
    --pop_sizes ${pop_sizes} --out_shape 2,44,128 --pop 0 |& tee logs/introgression_scans/format_${pop_pair}_ba.log

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations_withM/${pop_pair}_bi_filtered_sims/ \
    --ofile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_bi.hdf5 \
    --pop_sizes ${pop_sizes} --out_shape 2,44,128 --pop -1 |& tee logs/introgression_scans/format_${pop_pair}_bi.log

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations_withM/${pop_pair}_none_filtered_sims/ \
    --ofile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_none.hdf5 \
    --pop_sizes ${pop_sizes} --out_shape 2,44,128 --include_zeros |& tee logs/introgression_scans/format_${pop_pair}_none.log
```

## Check formatted simulations

I can create a fasta file to visually check the formatted simulations to see if they make sense using [write_fastas_from_hdf5.py](src/introgression_scans/write_fastas_from_hdf5.py):
```
conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_pair=lpa-eel

# mkdir data/introgression_scans/simulations_withM/fastas/
for mig in ab ba bi none; do
    mkdir data/introgression_scans/simulations_withM/fastas/${pop_pair}_${mig}
done

for mig in ab ba bi none; do
    python src/introgression_scans/write_fastas_from_hdf5.py \
        --ifile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_${mig}.hdf5 \
        --odir data/introgression_scans/simulations_withM/fastas/${pop_pair}_${mig} \
        --nseqs 25
done
```

## Train a discriminator model

To train a discriminator of my 4 classes of introgression I run [introNets train_discriminator.py](https://github.com/SchriderLab/introNets/blob/main/src/models/train_discriminator.py):

```
pop_pair=lpa-wel
script logs/introgression_scans/${pop_pair}_train_disc.log
conda activate ~/introNets/intronets
pop_pair=lpa-wel
taskset -c 1,2,3,4,5,6,7,8,9,10 \
    python src/introNets/src/models/train_discriminator.py \
        --idir data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/ --odir data/introgression_scans/${pop_pair}_discriminator_withM/ --n_classes 4

pop_pair=lpa-eel
script logs/introgression_scans/${pop_pair}_train_disc.log
conda activate ~/introNets/intronets
pop_pair=lpa-eel
taskset -c 11,12,13,14,15,16,17,18,19,20 \
    python src/introNets/src/models/train_discriminator.py \
        --idir data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/ --odir data/introgression_scans/${pop_pair}_discriminator_withM/ --n_classes 4

pop_pair=lpa-sel
script logs/introgression_scans/${pop_pair}_train_disc.log
conda activate ~/introNets/intronets
pop_pair=lpa-sel
mkdir data/introgression_scans/${pop_pair}_discriminator/
taskset -c 1,2,3,4,5,6,7,8,9,10 \
    python src/introNets/src/models/train_discriminator.py \
        --idir data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/ --odir data/introgression_scans/${pop_pair}_discriminator_withM/ --n_classes 4

```

## Evaluate the discriminator

To evaluate the model on additional simulations, I simulate data under each of the demographic models and each introgression scenario 100 times, filter the simulations to 128 SNPs and generate NPZ files to run the discriminator model on:
```
mkdir data/introgression_scans/evaluation_withM/
conda activate lynxtrogression_v2

for pop_pair in lpa-wel lpa-sel; do    
    if [ ${pop_pair} == 'lpa-wel' ]; then
        models=(12_9 6_2 20_7)
        pop_sizes="40,44"
    elif [ ${pop_pair} == 'lpa-eel' ]; then
        models=(34_7 38_4 30_1)
        pop_sizes="38,44"
    elif [ ${pop_pair} == 'lpa-sel' ]; then
        models=(12_6 18_7 18_10)
        pop_sizes="24,44"
    fi
    for model in ${models[@]}; do
        for migration in ab ba abba baab none; do
            
            # SIM DATA
            mkdir data/introgression_scans/evaluation_withM/${pop_pair}_${model}_${migration}
            python src/introgression_scans/simulate_data_withM.py \
                --demes_yaml data/demographic_inference/${pop_pair}_best_yamls/${pop_pair}_${model}_final_best_model.yaml \
                --confint data/demographic_inference/${pop_pair}_CI/${pop_pair}.${model}.CI.csv \
                --path_to_msmodified src/introNets/msmodified/ms \
                --migration ${migration} \
                --nreps 250 \
                --odir data/introgression_scans/evaluation_withM/${pop_pair}_${model}_${migration}
            
            # FILTER SIMS
            mkdir data/introgression_scans/evaluation_withM/${pop_pair}_${model}_${migration}/filtered
            if [ ${migration} == 'ab' ] || [ ${migration} == 'ba' ] || [ ${migration} == 'none' ]; then
                mig=${migration}
                nsims=100
            elif [ ${migration} == 'abba' ] || [ ${migration} == 'baab' ]; then
                mig="bi"
                nsims=50
            fi
            python src/introgression_scans/filter_sims.py \
                --idir data/introgression_scans/evaluation_withM/${pop_pair}_${model}_${migration} \
                --odir data/introgression_scans/evaluation_withM/${pop_pair}_${model}_${migration}/filtered \
                --n_sites 128 --n_sims ${nsims} --migration ${mig} --pop_sizes ${pop_sizes}
            
            # CREATE NPZ
            python src/introgression_scans/get_npz_from_sims.py \
                --idir data/introgression_scans/evaluation_withM/${pop_pair}_${model}_${migration}/filtered \
                --ofile data/introgression_scans/evaluation_withM/${pop_pair}_${model}_${migration}.npz \
                --pop_sizes ${pop_sizes}
        done
    done
done
```

Get predictions from these simulations:
```
conda activate ~/introNets/intronets

for pop_pair in lpa-wel lpa-sel; do    
    if [ ${pop_pair} == 'lpa-wel' ]; then
        models=(12_9 6_2 20_7)
        pop_sizes="40,44"
    elif [ ${pop_pair} == 'lpa-eel' ]; then
        models=(34_7 38_4 30_1)
        pop_sizes="38,44"
    elif [ ${pop_pair} == 'lpa-sel' ]; then
        models=(12_6 18_7 18_10)
        pop_sizes="24,44"
    fi
    for model in ${models[@]}; do
        for migration in ab ba abba baab none; do

            taskset -c 1 python src/introNets/src/models/apply_disc_to_npz.py \
                --ifile data/introgression_scans/evaluation_withM/${pop_pair}_${model}_${migration}.npz \
                --ofile data/introgression_scans/evaluation_withM/${pop_pair}_${model}_${migration}.predictions.csv \
                --weights data/introgression_scans/${pop_pair}_discriminator_withM/test.weights \
                --pop_sizes ${pop_sizes} \
                --shape 2,44,128 \
                --step_size 128 \
                --in_channels 2 \
                --n_classes 4
        
        done
    done
done
```

To plot them I run [plot_eval.py](src/introgression_scans/plot_eval.py):
```
for pop_pair in lpa-wel lpa-sel; do

    if [ ${pop_pair} == 'lpa-wel' ]; then
        models=(12_9 6_2 20_7)
    elif [ ${pop_pair} == 'lpa-eel' ]; then
        models=(34_7 38_4 30_1)
    elif [ ${pop_pair} == 'lpa-sel' ]; then
        models=(12_6 18_7 18_10)
    fi

    # for different threshold values
    for p in '0.95' '0.9' '0.85' '0.8' '0.75'; do
        pt=$(echo ${p} | tr '.' '_')
        # plot all models
        echo "plot all models ${p}"
        python src/introgression_scans/plot_eval.py \
            --idir data/introgression_scans/evaluation_withM \
            --pop_pair ${pop_pair} \
            --models $(for model in ${models[@]}; do echo ${model}; done | tr '\n' ',') \
            --pthresh ${p} \
            --oplot plots/introgression_scans/evaluation_withM/${pop_pair}.all_models.${pt}.cm.pdf
        # and then each model
        for model in ${models[@]}; do
            echo "plot ${model} ${p}"
            python src/introgression_scans/plot_eval.py \
                --idir data/introgression_scans/evaluation_withM \
                --pop_pair ${pop_pair} \
                --models ${model} \
                --pthresh ${p} \
                --oplot plots/introgression_scans/evaluation_withM/${pop_pair}.${model}.${pt}.cm.pdf
        done
    done
done
```


## Real data preparation

To transform the real data (phased vcf) to a hdf5 file that can be analyzed by the discriminator I first convert it to numpy's [NPZ](https://imageio.readthedocs.io/en/v2.5.0/format_npz.html) format. For this I use the [phasedVcfToNpz.py](src/introgression_scans/phasedVcfToNpz.py) script wrote by Dan. When using this script the `species1` will be saved as `sechHeader` + `sechMatrix` and `species2` as `simHeader` + `simMatrix` in the NPZ (important for hdf5 formatting below). One separate NPZ file is generated for each chromosome:
```
# vcfdir
vcfdir=/GRUPOS/grupolince/mLynRuf2.2_ref_vcfs
# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))
# eurasian pop
pop=wel
pop=eel
pop=sel
# vcf
vcfFileName=${vcfdir}/lynxtrogression_v2.autosomic_scaffolds.filter4.lpa-${pop}.ps.phased.merged.concat.fixed.afan.rd_fil.variant.vcf
# species1 - eurasian lynx
species1ListFileName=data/${pop}.list
# species2 - iberian lynx
species2ListFileName=data/lpa.list
# reference genome (masked if needed - not our case)
maskedRefFileName=${refdir}/mLynRuf2.2.revcomp.scaffolds.fa

for chr in ${chrs[@]}; do
    # output file
    npzFileName=data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz
    echo "generating ${npzFileName}"
    # run script
    python src/introgression_scans/phasedVcfToNpz.py \
        $vcfFileName $species1ListFileName $species2ListFileName $maskedRefFileName $chr $npzFileName
done
```

*THIS IS NOT WORKING AS INTENDED! THERE IS A BUG IN FORMAT_NPZ.PY*

I use [introNets format_npz.py](https://github.com/SchriderLab/introNets/blob/main/src/data/format_npz.py) to convert these files to hdf5. I set `--keys` to `sechMatrix,simMatrix` to have the eurasian lynx population as population1 and the iberian lynx population as population2.
```
conda activate ~/introNets/intronets

# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))
# eurasian pop
pop=wel

for chr in ${chrs[@]}; do
    in_npz=data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz
    out_hdf5=data/introgression_scans/hdf5_files/lpa-${pop}.${chr}.hdf5
    echo "generating ${out_hdf5}"
    mpirun -n 10 python src/introNets/src/data/format_npz.py \
        --verbose \
        --ifile ${in_npz} \
        --ofile ${out_hdf5} \
        --pop_sizes 40,44 --out_shape 2,44,128 \
        --keys sechMatrix,simMatrix
done
```

## NOT CURRENTLY WORKING - Apply discriminator to real data HDF5 - 

*THIS IS NOT WORKING AS INTENDED! THERE IS A BUG IN FORMAT_NPZ.PY*

To apply the discriminator model to the real data I wrote a modified version of [introNets apply_disc.py](https://github.com/SchriderLab/introNets/blob/main/src/models/apply_disc.py) which I located in the introNets folder for easier access to required imports. I put a copy of my version ([apply_disc_eb.py](src/introgression_scans/apply_disc_eb.py)) in this repo, but in order to work properly it has to be located in the `src/models/` folder of introNets.

```
conda activate ~/introNets/intronets

ifile=data/introgression_scans/hdf5_files/lpa-wel.mLynRuf2.2_ChrA1.hdf5
ofile=data/introgression_scans/lpa-wel_predictions/mLynRuf2.2_ChrA1.predictions.new.csv

python src/introNets/src/models/apply_disc_eb.py \
    --weights data/introgression_scans/discriminator/test.weights \
    --ifile ${ifile} \
    --ofile ${ofile}
```

## Apply discriminator to real data NPZ

Since there is a problem when generating the hdf5 file from npz data, until it's fixed I will use different script, [apply_disc_to_npz.py](src/introgression_scans/apply_disc_to_npz.py), that applies the model directly to the NPZ. This is not ideal since it's much slower in sorting the haplotypes in the windows because it's not being parallelized as in `format_npz.py`. I use it until the other is fixed. I placed a copy of it in the `src/models/` folder of introNets so it can load the model properly.

```
conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
conda activate ~/introNets/intronets
pop_pair=lpa-eel
pop_sizes="38,44"
conda activate ~/introNets/intronets
pop_pair=lpa-sel
pop_sizes="24,44"

mkdir data/introgression_scans/lpa-${pop}_predictions/

chr=mLynRuf2.2_ChrA1
chr=mLynRuf2.2_ChrC1
chr=mLynRuf2.2_ChrB1
chr=mLynRuf2.2_ChrA2_rc
chr=mLynRuf2.2_ChrC2
chr=mLynRuf2.2_ChrB2_rc
chr=mLynRuf2.2_ChrB3
chr=mLynRuf2.2_ChrB4_rc
chr=mLynRuf2.2_ChrA3_rc
chr=mLynRuf2.2_ChrD1
chr=mLynRuf2.2_ChrD4
chr=mLynRuf2.2_ChrD3
chr=mLynRuf2.2_ChrD2
chr=mLynRuf2.2_ChrF2
chr=mLynRuf2.2_ChrF1_rc
chr=mLynRuf2.2_ChrE2_rc
chr=mLynRuf2.2_ChrE1
chr=mLynRuf2.2_ChrE3_rc

taskset -c 1 python src/introNets/src/models/apply_disc_to_npz.py \
    --ifile data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz \
    --ofile data/introgression_scans/lpa-${pop}_predictions_withM/${chr}.predictions.csv \
    --weights data/introgression_scans/lpa-${pop}_discriminator_withM/test.weights \
    --pop_sizes ${pop_sizes} \
    --shape 2,44,128 \
    --step_size 64 \
    --in_channels 2 \
    --n_classes 4
```

## Create fastas from VCF to check predictions

To manually check predicted regions with introgression I run [src/introgression_scans/write_fastas_from_vcf.py](src/introgression_scans/write_fastas_from_vcf.py), then I can check them with an alignment viewer (I use [Jalview](https://www.jalview.org/)):
```
# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))
# vcfdir
vcfdir=/GRUPOS/grupolince/mLynRuf2.2_ref_vcfs
# eurasian pop
pop=wel
pop=eel
pop=sel
# ivcf
ivcf=${vcfdir}/lynxtrogression_v2.autosomic_scaffolds.filter4.lpa-${pop}.ps.phased.merged.concat.fixed.afan.rd_fil.variant.vcf

mkdir data/introgression_scans/lpa-${pop}_vcf_fastas/

for chr in ${chrs[@]}; do
    echo "fastas of ${chr}"
    mkdir data/introgression_scans/lpa-${pop}_vcf_fastas/${chr}
    python src/introgression_scans/write_fastas_from_vcf.py \
        --ivcf ${ivcf} \
        --chr ${chr} \
        --odir data/introgression_scans/lpa-${pop}_vcf_fastas/${chr} \
        --win_size 128 \
        --step_size 64
done
```

From NPZ

```
conda activate ~/introNets/intronets
pop=wel
pop_sizes="40,44"
conda activate ~/introNets/intronets
pop=eel
pop_sizes="38,44"
conda activate ~/introNets/intronets
pop=sel
pop_sizes="24,44"

# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))

mkdir data/introgression_scans/lpa-${pop}_binary_fastas/

for chr in ${chrs[@]}; do
    echo "writing binary fastas of ${chr}"
    # mkdir data/introgression_scans/lpa-${pop}_binary_fastas/${chr}
    python src/introNets/src/models/write_binary_fastas_from_npz.py \
        --ifile data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz \
        --odir data/introgression_scans/lpa-${pop}_binary_fastas/${chr} \
        --pop_sizes ${pop_sizes} \
        --shape 2,44,128 \
        --step_size 64
done
```

## Amount of introgression

The criteria we choose to identify a particular window to be introgressed in one direction is if the probability of introgression in that direction plus the probability of introgression in both directions is greater than 90%. After finding these windows, we additionally call as introgressed those windows which are adjacent to an introgressed window, and have as low as 70% probability to be introgressed as well.

I use the [get_intro_and_predbeds.py](src/introgression_scans/get_intro_and_predbeds.py) script to generate bed files of the introgressed windows in each direction. This generates 4 bed files:
`lpa_to_sel_intro.bed`, `lpa_to_wel_intro.bed`, `sel_to_lpa_intro.bed`, and `wel_to_lpa_intro.bed`.

I use bedtools to merge consecutive windows in these bed files and create two additional bed files. One has the regions in lpa that have introgression from both wel and sel. The other has the regions that have introgression from lpa in both wel and sel.
```
# autosome length : cat mLynRuf2.2.revcomp.scaffolds.fa.fai | grep "Chr" | grep -vE "ChrX|ChrY" | awk '{sum +=$2} END {print sum}' = 2285572469
for bed in $(ls data/introgression_scans/bed_files/*_intro.bed); do
    base=$(basename -s '.bed' ${bed})
    echo "${base}:"
    bedtools merge \
        -i data/introgression_scans/bed_files/${base}.bed \
        > data/introgression_scans/bed_files/${base}.merged.bed
    echo "$(awk '{sum += $3 - $2} END {print sum}' data/introgression_scans/bed_files/${base}.merged.bed) / 2285572469" | bc -l
done

# lpa_to_sel_intro:
# 0.02129420513246478031
# lpa_to_wel_intro:
# 0.06237726168550554062
# sel_to_lpa_intro:
# 0.04604777815076140558
# wel_to_lpa_intro:
# 0.05551230587560949483
```

Additionally, I also generate 3 more bed files:
  - wel exclusive regions in lpa
  - sel exclusive regions in lpa
  - regions with intro from both wel and sel in lpa (intersect)
  - regions with intro from either wel or sel in lpa (merge)
```
bedtools subtract \
    -a data/introgression_scans/bed_files/wel_to_lpa_intro.merged.bed \
    -b data/introgression_scans/bed_files/sel_to_lpa_intro.merged.bed \
    > data/introgression_scans/bed_files/wel_to_lpa_intro.exclusive.bed
echo "$(awk '{sum += $3 - $2} END {print sum}' data/introgression_scans/bed_files/wel_to_lpa_intro.exclusive.bed) / 2285572469" | bc -l
# 0.01917226016428709441

bedtools subtract \
    -a data/introgression_scans/bed_files/sel_to_lpa_intro.merged.bed \
    -b data/introgression_scans/bed_files/wel_to_lpa_intro.merged.bed \
    > data/introgression_scans/bed_files/sel_to_lpa_intro.exclusive.bed
echo "$(awk '{sum += $3 - $2} END {print sum}' data/introgression_scans/bed_files/sel_to_lpa_intro.exclusive.bed) / 2285572469" | bc -l
# 0.00970773243943900516

bedtools intersect \
    -a data/introgression_scans/bed_files/sel_to_lpa_intro.merged.bed \
    -b data/introgression_scans/bed_files/wel_to_lpa_intro.merged.bed \
    > data/introgression_scans/bed_files/wel_and_sel_to_lpa_intro.intersect.bed
echo "$(awk '{sum += $3 - $2} END {print sum}' data/introgression_scans/bed_files/wel_and_sel_to_lpa_intro.intersect.bed) / 2285572469" | bc -l
# 0.03634004571132240042

bedtools merge \
    -i <(cat data/introgression_scans/bed_files/sel_to_lpa_intro.merged.bed data/introgression_scans/bed_files/wel_to_lpa_intro.merged.bed | sort -k1,1 -k2,2n) \
    > data/introgression_scans/bed_files/wel_and_sel_to_lpa_intro.merge.bed
echo "$(awk '{sum += $3 - $2} END {print sum}' data/introgression_scans/bed_files/wel_and_sel_to_lpa_intro.merge.bed) / 2285572469" | bc -l
# 0.06522003831504850000
```

## Introgression and diversity along the chromosomes

To plot introgressed windows in each genome:
```
python src/introgression_scans/plot_chroms_intro.py \
    --ibed data/introgression_scans/bed_files/wel_and_sel_to_lpa_intro.merge.bed \
    --ofile plots/introgression_scans/intro_genomes/lpa.from_both.pdf

python src/introgression_scans/plot_chroms_intro.py \
    --ibed data/introgression_scans/bed_files/lpa_to_wel_intro.merged.bed \
    --ofile plots/introgression_scans/intro_genomes/wel.from_lpa.pdf

python src/introgression_scans/plot_chroms_intro.py \
    --ibed data/introgression_scans/bed_files/lpa_to_sel_intro.merged.bed \
    --ofile plots/introgression_scans/intro_genomes/sel.from_lpa.pdf
```



---
## TESTING TESTING 

To calculate pi along the genome in each population (100kb window size is selected):
```
# vcfdir
vcfdir=/GRUPOS/grupolince/mLynRuf2.2_ref_vcfs
# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))

# species1 - eurasian lynx
for pop in wel sel; do
    # vcf
    ivcf=${vcfdir}/lynxtrogression_v2.autosomic_scaffolds.filter4.lpa-${pop}.ps.phased.merged.concat.fixed.afan.rd_fil.variant.vcf
    pop1=data/${pop}.list
    
    # divide vcf per population
    vcftools --vcf $ivcf --keep $pop1 --maf 0.0001 \
        --recode --recode-INFO-all --out data/introgression_scans/${pop}
    
    # calculate pi per population
    vcftools --vcf data/introgression_scans/${pop}.recode.vcf \
        --window-pi 100000 --out data/introgression_scans/${pop}
done

# species2 - iberian lynx
pop2=data/lpa.list

# divide vcf per population
vcftools --vcf $ivcf --keep $pop2 --maf 0.0001 \
    --recode --recode-INFO-all --out data/introgression_scans/lpa
    
# calculate pi per population
vcftools --vcf data/introgression_scans/lpa.recode.vcf \
    --window-pi 100000 --out data/introgression_scans/lpa
```

Now to get bed files with 10kb windows along the genome, the probabilities of ab, ba and bi of all windows in the introscans (from the predictions csv) and the pi calculations (pi in 100kb windows):
```
# 10kb windows along the genome
bedtools makewindows -g data/mLynRuf2.2.revcomp.scaffolds.genome -w 10000 |
    sort -k1,1 -k2,2n > data/introgression_scans/bed_files/tenkb_windows.bed

# windows in introscans
for pop_pair in lpa-wel lpa-sel; do
    echo "$pop_pair"
    grep -v "chrom" data/introgression_scans/${pop_pair}_predictions_withM.csv |
        cut -d',' -f2,3,4,5 | tr ',' '\t' \
        > data/introgression_scans/bed_files/${pop_pair}.all_windows.p_ab.bed
    grep -v "chrom" data/introgression_scans/${pop_pair}_predictions_withM.csv |
        cut -d',' -f2,3,4,6 | tr ',' '\t' \
        > data/introgression_scans/bed_files/${pop_pair}.all_windows.p_ba.bed
    grep -v "chrom" data/introgression_scans/${pop_pair}_predictions_withM.csv |
        cut -d',' -f2,3,4,7 | tr ',' '\t' \
        > data/introgression_scans/bed_files/${pop_pair}.all_windows.p_bi.bed
done

# 100kb windows
for pop in lpa wel sel; do
    echo "$pop"
    grep -v "CHROM" data/introgression_scans/${pop}.windowed.pi |
        cut -f1,2,3,5 | awk '{print $1, $2-1, $3, $4}' | tr ' ' '\t' \
        > data/introgression_scans/bed_files/${pop}_diversity.100kb_windows.bed
done
```

To get the tables of each genome's (lpa, wel, sel) introgression and diversity:
```
# LPA
bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
    -b data/introgression_scans/bed_files/lpa_diversity.100kb_windows.bed \
    -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/lpa.pi.tenkb_windows.bed

bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
    -b data/introgression_scans/bed_files/lpa-wel.all_windows.p_ab.bed \
    -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/lpa.welab.tenkb_windows.bed

bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
    -b data/introgression_scans/bed_files/lpa-wel.all_windows.p_bi.bed \
    -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/lpa.welbi.tenkb_windows.bed

bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
    -b data/introgression_scans/bed_files/lpa-sel.all_windows.p_ab.bed \
    -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/lpa.selab.tenkb_windows.bed

bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
    -b data/introgression_scans/bed_files/lpa-sel.all_windows.p_bi.bed \
    -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/lpa.selbi.tenkb_windows.bed

# WEL
bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
    -b data/introgression_scans/bed_files/wel_diversity.100kb_windows.bed \
    -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/wel.pi.tenkb_windows.bed

bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
    -b data/introgression_scans/bed_files/lpa-wel.all_windows.p_ba.bed \
    -c 4 -o max | awk '$4 != "." {print}' > data/introgression_scans/bed_files/wel.welba.tenkb_windows.bed

bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
    -b data/introgression_scans/bed_files/lpa-wel.all_windows.p_bi.bed \
    -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/wel.welbi.tenkb_windows.bed

# SEL
    bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
        -b data/introgression_scans/bed_files/sel_diversity.100kb_windows.bed \
        -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/sel.pi.tenkb_windows.bed

    bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
        -b data/introgression_scans/bed_files/lpa-sel.all_windows.p_ba.bed \
        -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/sel.selba.tenkb_windows.bed

    bedtools map -a data/introgression_scans/bed_files/tenkb_windows.bed \
        -b data/introgression_scans/bed_files/lpa-sel.all_windows.p_bi.bed \
        -c 4 -o mean | awk '$4 != "." {print}' > data/introgression_scans/bed_files/sel.selbi.tenkb_windows.bed
```