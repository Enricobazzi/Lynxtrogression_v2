# Introgression Scans

## Download Intronets

I need [introNets](https://github.com/SchriderLab/introNets) version of ms (msmodified) to run the simulations_withM. I download the folder from github and compile msmodified as suggested by Dylan.
```
cd src
git clone https://github.com/SchriderLab/introNets.git
cd introNets/msmodified
gcc -o ms ms.c streec.c rand1.c -lm
```
To setup a conda environment to run its scripts:
```
## create environment
# on genomics cluster
conda create --prefix=/home/ebazzicalupo/introNets/intronets python=3.9
conda activate /home/ebazzicalupo/introNets/intronets
# on cesga cluster
conda create --prefix=/mnt/netapp1/Store_CSIC/home/csic/eye/eba/intronets python=3.9
conda activate /mnt/netapp1/Store_CSIC/home/csic/eye/eba/intronets

# install stuff:
conda install -c conda-forge mpi4py openmpi
pip install "numpy<1.25"
pip install seriate
pip install scipy
pip install scikit-learn
pip install h5py
python -m pip install -U matplotlib
pip uninstall protobuf
pip install "protobuf<3.20"
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install pandas
pip install seaborn
pip install prettytable
```

## Simulate training data

To simulate the data for training the [simulate_data.py](src/introgression_scans/simulate_data.py) takes a YAML file (`--demes_yaml`) with the demographic model in demes format (generated by GADMA2), a CSV (`--confint`) with the confidence intervals around the parameters (generated by [plot_boot_params.py](src/demographic_inference/plot_boot_params.py)), and a migration scenario (`--migration`, see below), and outputs a specified number of simulations_withM (`--nreps`) to an output directory (`--odir`), using a msmodified simulator (`--path_to_msmodified`).

The migration scenarios to be simulated are:
- ab: migration from population 1 (eurasian lynx) to population 2 (iberian lynx) in forward time (`-es Tmig 2 Pmig -ej Tmig 3 1`)
- ba: migration from population 2 (iberian lynx) to population 1 (eurasian lynx) in forward time (`-es Tmig 1 Pmig -ej Tmig 3 2`)
- abba: bidirectional migration, with first ab and then ba in forward time
- baab: bidiractional migration, with first ba and then ab in forward time
- none: no migration

The time of migration is set to be a random time between the present and 5 thousand generations ago and the amount of migration is a random value between 0.05 and 0.5.

Both abba and baab will go into the 'bi' category for the discriminator, but are divided here because of how you need to specify the order of migrations in ms. This means we will simulate X ab, ba and none, and X/2 abba and baab for each demographic model.

```
conda activate lynxtrogression_v2
pop_pair=lpa-eel
pop_pair=lpa-sel
pop_pair=lpa-wel

if [ ${pop_pair} == 'lpa-wel' ]; then
    models=(12_9 6_2 20_7)
elif [ ${pop_pair} == 'lpa-eel' ]; then
    models=(34_7 38_4 30_1)
elif [ ${pop_pair} == 'lpa-sel' ]; then
    models=(12_6 18_7 18_10)
fi

for migration in ab ba bi none; do
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_sims/
done

for model in ${models[@]}; do
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_ab_sims/${model}/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_ba_sims/${model}/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_bi_sims/${model}_abba/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_bi_sims/${model}_baab/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_none_sims/${model}/
done

for migration in ab ba none; do
    for model in ${models[@]}; do
        python src/introgression_scans/simulate_data_withM.py \
            --demes_yaml data/demographic_inference/${pop_pair}_best_yamls/${pop_pair}_${model}_final_best_model.yaml \
            --confint data/demographic_inference/${pop_pair}_CI/${pop_pair}.${model}.CI.csv \
            --path_to_msmodified src/introNets/msmodified/ms \
            --migration ${migration} \
            --nreps 20000 \
            --odir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_sims/${model}/
    done
done

for migration in abba baab; do
    for model in ${models[@]}; do
        python src/introgression_scans/simulate_data.py \
            --demes_yaml data/demographic_inference/${pop_pair}_best_yamls/${pop_pair}_${model}_final_best_model.yaml \
            --confint data/demographic_inference/${pop_pair}_CI/${pop_pair}.${model}.CI.csv \
            --path_to_msmodified src/introNets/msmodified/ms \
            --migration ${migration} \
            --nreps 10000 \
            --odir data/introgression_scans/simulations_withM/${pop_pair}_bi_sims/${model}_${migration}/
    done
done
```

## Filter simulated data for training

I filter out from simulations_withM the ones with < 128 segsites using [filter_sims.py](src/introgression_scans/filter_sims.py), or [introNets format.py](https://github.com/SchriderLab/introNets/blob/main/src/data/format.py) will throw errors and corrupt the hdf5 file:
```
conda activate lynxtrogression_v2
pop_pair=lpa-wel
pop_sizes="40,44"
conda activate lynxtrogression_v2
pop_pair=lpa-eel
pop_sizes="38,44"
conda activate lynxtrogression_v2
pop_pair=lpa-sel
pop_sizes="24,44"

if [ ${pop_pair} == 'lpa-wel' ]; then
    models=(12_9 6_2 20_7)
elif [ ${pop_pair} == 'lpa-eel' ]; then
    models=(34_7 38_4 30_1)
elif [ ${pop_pair} == 'lpa-sel' ]; then
    models=(12_6 18_7 18_10)
fi


for migration in ab ba bi none; do
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_filtered_sims/
done

for model in ${models[@]}; do
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_ab_filtered_sims/${model}/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_ba_filtered_sims/${model}/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_bi_filtered_sims/${model}_abba/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_bi_filtered_sims/${model}_baab/
    mkdir data/introgression_scans/simulations_withM/${pop_pair}_none_filtered_sims/${model}/
done

for migration in ab ba none; do
    for model in ${models[@]}; do
        echo "filtering ${pop_pair}_${migration} of ${model}"
        python src/introgression_scans/filter_sims.py \
            --idir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_sims/${model}/ \
            --odir data/introgression_scans/simulations_withM/${pop_pair}_${migration}_filtered_sims/${model}/ \
            --n_sites 129 --n_sims 12000 --migration ${migration} --pop_sizes ${pop_sizes}
    done
done

for model in ${models[@]}; do
    for migration in abba baab; do
        echo "filtering ${pop_pair}_${migration} of ${model}"
        python src/introgression_scans/filter_sims.py \
            --idir data/introgression_scans/simulations_withM/${pop_pair}_bi_sims/${model}_${migration}/ \
            --odir data/introgression_scans/simulations_withM/${pop_pair}_bi_filtered_sims/${model}_${migration}/ \
            --n_sites 129 --n_sims 6000 --migration bi --pop_sizes ${pop_sizes}
    done
done
```

## Format simulations_withM

To format my simulations_withM for training I run [introNets format.py](https://github.com/SchriderLab/introNets/blob/main/src/data/format.py):
```
## ADD HDF5 FOLDER TO OFOLDER

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
conda activate ~/introNets/intronets
pop_pair=lpa-eel
pop_sizes="38,44"
conda activate ~/introNets/intronets
pop_pair=lpa-sel
pop_sizes="24,44"

mkdir data/introgression_scans/simulations_withM/${pop_pair}_hdf5s

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations_withM/${pop_pair}_ab_filtered_sims/ \
    --ofile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_ab.hdf5 \
    --pop_sizes ${pop_sizes} --out_shape 2,44,128 --pop 1 |& tee logs/introgression_scans/format_${pop_pair}_ab.log

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations_withM/${pop_pair}_ba_filtered_sims/ \
    --ofile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_ba.hdf5 \
    --pop_sizes ${pop_sizes} --out_shape 2,44,128 --pop 0 |& tee logs/introgression_scans/format_${pop_pair}_ba.log

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations_withM/${pop_pair}_bi_filtered_sims/ \
    --ofile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_bi.hdf5 \
    --pop_sizes ${pop_sizes} --out_shape 2,44,128 --pop -1 |& tee logs/introgression_scans/format_${pop_pair}_bi.log

conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
mpirun -n 4 python src/introNets/src/data/format.py \
    --verbose \
    --idir data/introgression_scans/simulations_withM/${pop_pair}_none_filtered_sims/ \
    --ofile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_none.hdf5 \
    --pop_sizes ${pop_sizes} --out_shape 2,44,128 --include_zeros |& tee logs/introgression_scans/format_${pop_pair}_none.log
```

## Check formatted simulations

I can create a fasta file to visually check the formatted simulations to see if they make sense using [write_fastas_from_hdf5.py](src/introgression_scans/write_fastas_from_hdf5.py):
```
conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_pair=lpa-eel

# mkdir data/introgression_scans/simulations_withM/fastas/
for mig in ab ba bi none; do
    mkdir data/introgression_scans/simulations_withM/fastas/${pop_pair}_${mig}
done

for mig in ab ba bi none; do
    python src/introgression_scans/write_fastas_from_hdf5.py \
        --ifile data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/${pop_pair}_${mig}.hdf5 \
        --odir data/introgression_scans/simulations_withM/fastas/${pop_pair}_${mig} \
        --nseqs 25
done
```

## Train a discriminator model

To train a discriminator of my 4 classes of introgression I run [introNets train_discriminator.py](https://github.com/SchriderLab/introNets/blob/main/src/models/train_discriminator.py):

```
pop_pair=lpa-wel
script logs/introgression_scans/${pop_pair}_train_disc.log
conda activate ~/introNets/intronets
pop_pair=lpa-wel
taskset -c 1,2,3,4,5,6,7,8,9,10 \
    python src/introNets/src/models/train_discriminator.py \
        --idir data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/ --odir data/introgression_scans/${pop_pair}_discriminator_withM/ --n_classes 4

pop_pair=lpa-eel
script logs/introgression_scans/${pop_pair}_train_disc.log
conda activate ~/introNets/intronets
pop_pair=lpa-eel
taskset -c 11,12,13,14,15,16,17,18,19,20 \
    python src/introNets/src/models/train_discriminator.py \
        --idir data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/ --odir data/introgression_scans/${pop_pair}_discriminator_withM/ --n_classes 4

pop_pair=lpa-sel
script logs/introgression_scans/${pop_pair}_train_disc.log
conda activate ~/introNets/intronets
pop_pair=lpa-sel
mkdir data/introgression_scans/${pop_pair}_discriminator/
taskset -c 1,2,3,4,5,6,7,8,9,10 \
    python src/introNets/src/models/train_discriminator.py \
        --idir data/introgression_scans/simulations_withM/${pop_pair}_hdf5s/ --odir data/introgression_scans/${pop_pair}_discriminator_withM/ --n_classes 4

```

## Evaluate the discriminator

TBD

## Real data preparation

To transform the real data (phased vcf) to a hdf5 file that can be analyzed by the discriminator I first convert it to numpy's [NPZ](https://imageio.readthedocs.io/en/v2.5.0/format_npz.html) format. For this I use the [phasedVcfToNpz.py](src/introgression_scans/phasedVcfToNpz.py) script wrote by Dan. When using this script the `species1` will be saved as `sechHeader` + `sechMatrix` and `species2` as `simHeader` + `simMatrix` in the NPZ (important for hdf5 formatting below). One separate NPZ file is generated for each chromosome:
```
# vcfdir
vcfdir=/GRUPOS/grupolince/mLynRuf2.2_ref_vcfs
# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))
# eurasian pop
pop=wel
pop=eel
pop=sel
# vcf
vcfFileName=${vcfdir}/lynxtrogression_v2.autosomic_scaffolds.filter4.lpa-${pop}.ps.phased.merged.concat.fixed.afan.rd_fil.variant.vcf
# species1 - eurasian lynx
species1ListFileName=data/${pop}.list
# species2 - iberian lynx
species2ListFileName=data/lpa.list
# reference genome (masked if needed - not our case)
maskedRefFileName=${refdir}/mLynRuf2.2.revcomp.scaffolds.fa

for chr in ${chrs[@]}; do
    # output file
    npzFileName=data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz
    echo "generating ${npzFileName}"
    # run script
    python src/introgression_scans/phasedVcfToNpz.py \
        $vcfFileName $species1ListFileName $species2ListFileName $maskedRefFileName $chr $npzFileName
done
```

I use [introNets format_npz.py](https://github.com/SchriderLab/introNets/blob/main/src/data/format_npz.py) to convert these files to hdf5. I set `--keys` to `sechMatrix,simMatrix` to have the eurasian lynx population as population1 and the iberian lynx population as population2.
```
conda activate ~/introNets/intronets

# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))
# eurasian pop
pop=wel

for chr in ${chrs[@]}; do
    in_npz=data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz
    out_hdf5=data/introgression_scans/hdf5_files/lpa-${pop}.${chr}.hdf5
    echo "generating ${out_hdf5}"
    mpirun -n 10 python src/introNets/src/data/format_npz.py \
        --verbose \
        --ifile ${in_npz} \
        --ofile ${out_hdf5} \
        --pop_sizes 40,44 --out_shape 2,44,128 \
        --keys sechMatrix,simMatrix
done
```

## NOT CURRENTLY WORKING - Apply discriminator to real data HDF5 - 

*THIS IS NOT WORKING AS INTENDED! THERE IS A BUG IN FORMAT_NPZ.PY*

To apply the discriminator model to the real data I wrote a modified version of [introNets apply_disc.py](https://github.com/SchriderLab/introNets/blob/main/src/models/apply_disc.py) which I located in the introNets folder for easier access to required imports. I put a copy of my version ([apply_disc_eb.py](src/introgression_scans/apply_disc_eb.py)) in this repo, but in order to work properly it has to be located in the `src/models/` folder of introNets.

```
conda activate ~/introNets/intronets

ifile=data/introgression_scans/hdf5_files/lpa-wel.mLynRuf2.2_ChrA1.hdf5
ofile=data/introgression_scans/lpa-wel_predictions/mLynRuf2.2_ChrA1.predictions.new.csv

python src/introNets/src/models/apply_disc_eb.py \
    --weights data/introgression_scans/discriminator/test.weights \
    --ifile ${ifile} \
    --ofile ${ofile}
```

## Apply discriminator to real data NPZ

Since there is a problem when generating the hdf5 file from npz data, until it's fixed I will use different script, [apply_disc_to_npz.py](src/introgression_scans/apply_disc_to_npz.py), that applies the model directly to the NPZ. This is not ideal since it's much slower in sorting the haplotypes in the windows because it's not being parallelized as in `format_npz.py`. I use it until the other is fixed. I placed a copy of it in the `src/models/` folder of introNets so it can load the model properly.

```
conda activate ~/introNets/intronets
pop_pair=lpa-wel
pop_sizes="40,44"
conda activate ~/introNets/intronets
pop_pair=lpa-eel
pop_sizes="38,44"
conda activate ~/introNets/intronets
pop_pair=lpa-sel
pop_sizes="24,44"

mkdir data/introgression_scans/lpa-${pop}_predictions/

chr=mLynRuf2.2_ChrA1
chr=mLynRuf2.2_ChrC1
chr=mLynRuf2.2_ChrB1
chr=mLynRuf2.2_ChrA2_rc
chr=mLynRuf2.2_ChrC2
chr=mLynRuf2.2_ChrB2_rc
chr=mLynRuf2.2_ChrB3
chr=mLynRuf2.2_ChrB4_rc
chr=mLynRuf2.2_ChrA3_rc
chr=mLynRuf2.2_ChrD1
chr=mLynRuf2.2_ChrD4
chr=mLynRuf2.2_ChrD3
chr=mLynRuf2.2_ChrD2
chr=mLynRuf2.2_ChrF2
chr=mLynRuf2.2_ChrF1_rc
chr=mLynRuf2.2_ChrE2_rc
chr=mLynRuf2.2_ChrE1
chr=mLynRuf2.2_ChrE3_rc

python src/introNets/src/models/apply_disc_to_npz.py \
    --ifile data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz \
    --ofile data/introgression_scans/lpa-${pop}_predictions/${chr}.predictions.csv \
    --weights data/introgression_scans/lpa-${pop}_discriminator/test.weights \
    --pop_sizes ${pop_sizes} \
    --shape 2,44,128 \
    --step_size 64 \
    --in_channels 2 \
    --n_classes 4
```

## Create fastas from VCF to check predictions

To manually check predicted regions with introgression I run [src/introgression_scans/write_fastas_from_vcf.py](src/introgression_scans/write_fastas_from_vcf.py), then I can check them with an alignment viewer (I use [Jalview](https://www.jalview.org/)):
```
# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))
# vcfdir
vcfdir=/GRUPOS/grupolince/mLynRuf2.2_ref_vcfs
# eurasian pop
pop=wel
pop=eel
pop=sel
# ivcf
ivcf=${vcfdir}/lynxtrogression_v2.autosomic_scaffolds.filter4.lpa-${pop}.ps.phased.merged.concat.fixed.afan.rd_fil.variant.vcf

mkdir data/introgression_scans/lpa-${pop}_vcf_fastas/

for chr in ${chrs[@]}; do
    echo "fastas of ${chr}"
    mkdir data/introgression_scans/lpa-${pop}_vcf_fastas/${chr}
    python src/introgression_scans/write_fastas_from_vcf.py \
        --ivcf ${ivcf} \
        --chr ${chr} \
        --odir data/introgression_scans/lpa-${pop}_vcf_fastas/${chr} \
        --win_size 128 \
        --step_size 64
done
```

From NPZ

```
conda activate ~/introNets/intronets
pop=wel
pop_sizes="40,44"
conda activate ~/introNets/intronets
pop=eel
pop_sizes="38,44"
conda activate ~/introNets/intronets
pop=sel
pop_sizes="24,44"

# refdir
refdir=/GRUPOS/grupolince/reference_genomes/lynx_rufus_mLynRuf2.2
# chrs
chrs=($(cat ${refdir}/autosomic_scaffolds_list.txt))

mkdir data/introgression_scans/lpa-${pop}_binary_fastas/

for chr in ${chrs[@]}; do
    echo "writing binary fastas of ${chr}"
    # mkdir data/introgression_scans/lpa-${pop}_binary_fastas/${chr}
    python src/introNets/src/models/write_binary_fastas_from_npz.py \
        --ifile data/introgression_scans/npz_files/lpa-${pop}.${chr}.npz \
        --odir data/introgression_scans/lpa-${pop}_binary_fastas/${chr} \
        --pop_sizes ${pop_sizes} \
        --shape 2,44,128 \
        --step_size 64
done
```

## Amount of introgression



